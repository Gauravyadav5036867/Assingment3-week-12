{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88aae38-7920-42ad-920b-18becf36e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1\n",
    "\n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means among three or more groups. It is an extension of the t-test for comparing means of two groups to situations where there are multiple groups. To use ANOVA effectively, certain assumptions need to be met:\n",
    "\n",
    "Independence: Observations within each group must be independent of each other. This means that the data points in one group should not influence the data points in another group.\n",
    "\n",
    "Normality: The data within each group should follow a normal distribution. This assumption is especially important when the sample sizes are small (typically less than 30 in each group), as violations of normality can affect the validity of the results.\n",
    "\n",
    "Homogeneity of Variances (Homoscedasticity): The variances of the different groups should be equal. This means that the spread or dispersion of data points should be roughly the same across all groups. Violations of this assumption can lead to inflated Type I error rates and affect the validity of the F-test in ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fe5ad-3208-4a0b-bf83-2365a18801f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "One-Way ANOVA: One-Way ANOVA is used when you have one independent variable with three or more levels (groups or categories) and you want to compare the means of a single dependent variable across these groups. It is used to determine whether there are any statistically significant differences between the means of the groups.\n",
    "\n",
    "Example: Suppose you want to compare the average test scores of students across three different teaching methods (e.g., traditional lecture, online tutorial, and interactive workshop).\n",
    "\n",
    "Two-Way ANOVA: Two-Way ANOVA is used when you have two independent variables (factors) and one dependent variable. It allows you to examine the main effects of each independent variable as well as the interaction effect between them. The two independent variables can be either categorical or continuous.\n",
    "\n",
    "Example: Suppose you want to study the effects of both gender and treatment type on exam scores. Gender (male/female) and Treatment type (A/B) are the two independent variables, and exam score is the dependent variable.\n",
    "\n",
    "Repeated Measures ANOVA: Repeated Measures ANOVA is used when you have a single group of participants and you measure them on the same dependent variable at multiple time points or under different conditions. It is designed to assess whether there are any statistically significant differences in the means of the dependent variable across the different time points or conditions.\n",
    "\n",
    "Example: Suppose you want to investigate the effects of a new drug treatment on patients' pain levels over time. You measure the pain levels of each patient before treatment, immediately after treatment, and then at regular intervals afterward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c859f-7c79-499f-89da-1f678ccea133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3\n",
    "\n",
    "In ANOVA (Analysis of Variance), variance is partitioned into different components to understand the sources of variability in the data. This partitioning is essential for understanding the contributions of different factors to the overall variability observed in the data. The total variance observed in the data is decomposed into several components:\n",
    "\n",
    "Total Variance (Total Sum of Squares, SST): This represents the total variability observed in the data across all groups. It is calculated as the sum of squared deviations of individual data points from the overall mean.\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SST=∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " (X \n",
    "i\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Between-Group Variance (Between-Group Sum of Squares, SSB): This represents the variability between the group means. It is calculated as the sum of squared deviations of group means from the overall mean, weighted by the number of observations in each group.\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "ˉ\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SSB=∑ \n",
    "j=1\n",
    "k\n",
    "​\n",
    " n \n",
    "j\n",
    "​\n",
    " ( \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Within-Group Variance (Within-Group Sum of Squares, SSW or SSE): This represents the variability within each group or treatment condition. It is calculated as the sum of squared deviations of individual data points from their respective group means.\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    "�\n",
    ")\n",
    "2\n",
    "SSW=∑ \n",
    "j=1\n",
    "k\n",
    "​\n",
    " ∑ \n",
    "i=1\n",
    "n \n",
    "j\n",
    "​\n",
    " \n",
    "​\n",
    " (X \n",
    "ij\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "The total variance (SST) can be decomposed into the sum of the between-group variance (SSB) and the within-group variance (SSW):\n",
    "\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "+\n",
    "�\n",
    "�\n",
    "�\n",
    "SST=SSB+SSW\n",
    "\n",
    "Understanding the partitioning of variance in ANOVA is important for several reasons:\n",
    "\n",
    "Identifying Sources of Variability: By decomposing the total variance into between-group and within-group components, ANOVA helps identify the sources of variability in the data. This allows researchers to determine if differences between group means are due to the effect of the independent variable (treatment) or random variability within groups.\n",
    "\n",
    "Assessing the Importance of Factors: ANOVA quantifies the relative contributions of different factors to the total variability observed in the data. This helps researchers assess the importance of various factors and their interactions in explaining the observed differences between groups.\n",
    "\n",
    "Evaluating Model Fit: Understanding the partitioning of variance allows researchers to assess the fit of the ANOVA model to the data. A good fit indicates that the model adequately accounts for the observed variability, while a poor fit suggests that additional factors may need to be considered or that the assumptions of the ANOVA model may be violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c1d36b-1abf-4df6-a8ad-e9179d453259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4\n",
    "\n",
    "To calculate the Total Sum of Squares (SST), Explained Sum of Squares (SSE), and Residual Sum of Squares (SSR) in a one-way ANOVA using Python, you can use the following approach:\n",
    "\n",
    "Calculate the Total Sum of Squares (SST):\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SST=∑ \n",
    "i=1\n",
    "n\n",
    "​\n",
    " (X \n",
    "i\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Calculate the Explained Sum of Squares (SSE):\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "ˉ\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    ")\n",
    "2\n",
    "SSE=∑ \n",
    "j=1\n",
    "k\n",
    "​\n",
    " n \n",
    "j\n",
    "​\n",
    " ( \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Calculate the Residual Sum of Squares (SSR):\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    "�\n",
    "−\n",
    "�\n",
    "ˉ\n",
    "�\n",
    ")\n",
    "2\n",
    "SSR=∑ \n",
    "j=1\n",
    "k\n",
    "​\n",
    " ∑ \n",
    "i=1\n",
    "n \n",
    "j\n",
    "​\n",
    " \n",
    "​\n",
    " (X \n",
    "ij\n",
    "​\n",
    " − \n",
    "X\n",
    "ˉ\n",
    "  \n",
    "j\n",
    "​\n",
    " ) \n",
    "2\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (group means and individual observations)\n",
    "group_means = [80, 75, 85]  # Example group means\n",
    "group_sizes = [20, 25, 30]   # Example group sizes\n",
    "observations = [[79, 82, 78, 83, 81, 80, 78, 79, 81, 83, 84, 82, 79, 80, 81, 84, 82, 81, 79, 80],  # Example observations for group 1\n",
    "                [75, 76, 78, 74, 75, 76, 77, 74, 75, 76, 77, 75, 76, 78, 74, 75, 76, 77, 75, 76, 78, 74, 75, 76, 77, 75],  # Example observations for group 2\n",
    "                [84, 86, 85, 83, 84, 85, 86, 85, 83, 84, 85, 86, 85, 83, 84, 85, 86, 85, 83, 84, 85, 86, 85, 83, 84, 85, 86, 85, 83, 84, 85]]  # Example observations for group 3\n",
    "\n",
    "# Convert observations to a flat list\n",
    "observations_flat = [obs for group in observations for obs in group]\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(observations_flat)\n",
    "\n",
    "# Calculate Total Sum of Squares (SST)\n",
    "SST = np.sum((np.array(observations_flat) - overall_mean) ** 2)\n",
    "\n",
    "# Calculate Explained Sum of Squares (SSE)\n",
    "SSE = np.sum(group_sizes * (np.array(group_means) - overall_mean) ** 2)\n",
    "\n",
    "# Calculate Residual Sum of Squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977c4ab-810c-4bb8-bb1c-21ea8ebf3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (example)\n",
    "data = {'A': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'B': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "        'Y': [10, 12, 15, 9, 11, 14, 8, 10, 13]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Y ~ C(A) + C(B) + C(A):C(B)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects\n",
    "main_effects = anova_table[['sum_sq', 'df', 'F', 'PR(>F)']][:-1]\n",
    "interaction_effect = anova_table.loc['C(A):C(B)', ['sum_sq', 'df', 'F', 'PR(>F)']]\n",
    "\n",
    "print(\"Main Effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3153fd7-ff14-4fe6-a96d-c5bb9043a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6\n",
    "\n",
    "In a one-way ANOVA, the F-statistic is used to test the null hypothesis that the means of the groups are equal against the alternative hypothesis that at least one of the group means is different. The p-value associated with the F-statistic indicates the probability of observing the data, or more extreme data, under the null hypothesis.\n",
    "\n",
    "In your scenario, the obtained F-statistic is 5.23 and the associated p-value is 0.02. Here's how you can interpret these results:\n",
    "\n",
    "F-statistic: The F-statistic measures the ratio of the between-group variance to the within-group variance. A larger F-statistic indicates a larger difference between the group means relative to the variation within groups. In this case, the F-statistic of 5.23 suggests that there is some difference between the group means.\n",
    "\n",
    "p-value: The p-value associated with the F-statistic is 0.02. This is the probability of observing the data, or more extreme data, if the null hypothesis (that the group means are equal) is true. Since the p-value is less than the significance level (typically 0.05), we reject the null hypothesis.\n",
    "\n",
    "Based on these results, we can conclude that there are statistically significant differences between the groups. In other words, at least one of the group means is different from the others. However, the ANOVA test does not tell us which specific group or groups are different from each other. To determine this, post-hoc tests such as Tukey's HSD or Bonferroni correction can be conducted to perform pairwise comparisons between group means. These tests help identify which specific group differences are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278ad9b-ce05-4f1f-850e-e065d5f17f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7\n",
    "In a repeated measures ANOVA, missing data can occur when participants have incomplete responses at one or more time points. Handling missing data appropriately is crucial to ensure the validity and reliability of the results. Here are some common methods for handling missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "In this approach, cases with missing data for any time point are excluded from the analysis.\n",
    "Pros: Simple to implement, does not require any additional assumptions.\n",
    "Cons: Reduces sample size and statistical power, potentially introduces bias if missing data are not missing completely at random (MCAR).\n",
    "Pairwise Deletion (Available Case Analysis):\n",
    "\n",
    "In this approach, only cases with complete data for each pairwise comparison are used in each analysis.\n",
    "Pros: Retains more data compared to complete case analysis, can provide more precise estimates.\n",
    "Cons: May result in different sample sizes for different comparisons, potentially leading to biased estimates if missingness is not MCAR.\n",
    "Mean Imputation:\n",
    "\n",
    "Missing values are replaced with the mean of the available data for the corresponding variable.\n",
    "Pros: Preserves sample size, simple to implement.\n",
    "Cons: Can introduce bias by underestimating the variability, assumes missing values have the same mean as observed values, can distort relationships between variables.\n",
    "Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Missing values are replaced with the last observed value for the same participant.\n",
    "Pros: Preserves sample size, maintains temporal relationships in longitudinal data.\n",
    "Cons: May underestimate variability, assumes missing values remain constant over time, may not be appropriate for all types of missing data patterns.\n",
    "Multiple Imputation:\n",
    "\n",
    "Missing values are imputed multiple times based on observed data and the uncertainty associated with missingness.\n",
    "Pros: Provides more accurate estimates compared to single imputation methods, preserves variability, handles missingness under different mechanisms.\n",
    "Cons: More complex to implement, requires assumptions about the missing data mechanism, can be computationally intensive.\n",
    "Model-Based Imputation:\n",
    "\n",
    "Missing values are imputed using a statistical model estimated from observed data.\n",
    "Pros: Provides estimates based on the underlying data structure, can incorporate information from other variables.\n",
    "Cons: Requires specifying an appropriate model, may be sensitive to misspecification, can be computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286dd02-10f1-4792-87d6-bef9bd68ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 8\n",
    "\n",
    "In a repeated measures ANOVA, missing data can occur when some participants have incomplete data for one or more measurement points. Handling missing data appropriately is crucial to ensure the validity of the analysis. Here are some common methods to handle missing data in repeated measures ANOVA:\n",
    "\n",
    "Complete Case Analysis (Listwise Deletion): This approach involves excluding cases with missing data from the analysis. While straightforward, this method can lead to biased results if the missing data are not missing completely at random (MCAR), particularly if the missingness is related to the outcome variable.\n",
    "\n",
    "Pairwise Deletion (Available Case Analysis): With this approach, only the available data for each comparison are used in the analysis. This method maximizes the use of available data but can lead to loss of statistical power and biased estimates if the missing data are related to the outcome variable.\n",
    "\n",
    "Imputation: Imputation methods involve replacing missing values with estimated values. Common imputation methods include mean imputation (replacing missing values with the mean of the observed values), median imputation, and multiple imputation (creating multiple plausible imputed datasets). Imputation methods can help preserve statistical power and reduce bias but may introduce additional uncertainty, particularly if the missing data mechanism is not MCAR.\n",
    "\n",
    "Model-Based Methods: These methods involve modeling the relationship between the variables to predict missing values. For example, regression-based imputation involves regressing the missing variable on other variables with complete data to predict the missing values. Model-based methods can provide more accurate estimates but require strong assumptions about the data-generating process.\n",
    "\n",
    "The choice of method for handling missing data depends on various factors, including the mechanism of missingness, the amount of missing data, and the research context. It is essential to carefully consider the implications of each method and conduct sensitivity analyses to assess the robustness of the results.\n",
    "\n",
    "As for the potential consequences of using different methods to handle missing data, using complete case analysis or pairwise deletion may result in biased estimates and reduced statistical power, especially if the missing data are not missing completely at random. Imputation methods can introduce additional uncertainty and may not fully account for the missing data mechanism. Model-based methods may provide more accurate estimates but require strong assumptions about the underlying data-generating process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e090e56-9025-48e1-8d74-fc2ada0f66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 9\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data (mean weight loss for each diet)\n",
    "diet_A = np.array([2.5, 3.1, 4.0, 2.8, 3.5, 2.0, 3.2, 2.7, 3.6, 3.0,\n",
    "                   2.8, 3.4, 3.7, 3.2, 2.9, 3.1, 2.6, 3.5, 3.3, 3.8,\n",
    "                   3.1, 3.2, 3.0, 2.9, 2.5, 3.3, 3.6, 3.1, 2.7, 2.8,\n",
    "                   2.6, 3.2, 2.9, 3.4, 3.1, 2.7, 3.3, 3.0, 3.2, 2.8,\n",
    "                   3.5, 3.1, 3.6, 2.9, 3.2, 3.4, 2.7, 3.1, 2.8])\n",
    "diet_B = np.array([2.1, 2.8, 1.9, 2.5, 3.0, 2.4, 2.3, 1.8, 2.2, 2.7,\n",
    "                   2.3, 2.6, 2.5, 2.1, 2.4, 2.0, 2.9, 2.3, 2.8, 2.2,\n",
    "                   2.6, 2.4, 2.7, 2.1, 2.3, 2.5, 2.8, 2.0, 2.4, 2.6,\n",
    "                   2.3, 2.7, 2.1, 2.5, 2.2, 2.6, 2.0, 2.3, 2.8, 2.4,\n",
    "                   2.6, 2.1, 2.7, 2.3, 2.5, 2.2, 2.9, 2.4, 2.7, 2.0])\n",
    "diet_C = np.array([1.8, 2.2, 1.7, 2.0, 2.4, 1.9, 1.6, 1.5, 1.9, 2.1,\n",
    "                   1.8, 2.3, 2.1, 1.7, 2.0, 1.6, 2.2, 1.8, 2.1, 1.9,\n",
    "                   2.0, 1.6, 2.3, 1.7, 1.9, 2.2, 2.1, 1.8, 1.7, 2.0,\n",
    "                   1.9, 2.4, 1.8, 1.6, 2.2, 2.0, 1.5, 1.7, 1.9, 2.1,\n",
    "                   2.3, 2.0, 1.6, 2.2, 1.8, 1.9, 2.1, 1.7, 2.0, 1.8])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f6c3f-1379-4d82-888a-426645a2505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Sample data (example)\n",
    "data = {'Software': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'] * 10,\n",
    "        'Experience': ['Novice', 'Experienced'] * 15 * 3,\n",
    "        'Time': [np.random.normal(loc=30, scale=5) for _ in range(30)] +\n",
    "                [np.random.normal(loc=25, scale=4) for _ in range(30)] +\n",
    "                [np.random.normal(loc=35, scale=6) for _ in range(30)]}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the ANOVA model\n",
    "model = ols('Time ~ C(Software) + C(Experience) + C(Software):C(Experience)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "f_statistics = anova_table['F']\n",
    "p_values = anova_table['PR(>F)']\n",
    "\n",
    "print(\"F-statistics:\")\n",
    "print(f_statistics)\n",
    "print(\"\\nP-values:\")\n",
    "print(p_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b420abf4-7d6c-4f91-a4ef-67fdd0bbf6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 11\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data (test scores for control and experimental groups)\n",
    "control_group = np.array([75, 80, 82, 78, 79, 81, 76, 77, 74, 78, 80,\n",
    "                          77, 79, 83, 81, 80, 75, 78, 79, 80, 81,\n",
    "                          78, 76, 79, 82, 80, 79, 78, 81, 77, 80,\n",
    "                          78, 79, 80, 81, 82, 77, 78, 80, 79, 81,\n",
    "                          80, 75, 79, 78, 80, 76, 77, 79, 80, 81])\n",
    "\n",
    "experimental_group = np.array([85, 87, 88, 84, 86, 82, 85, 89, 83, 85,\n",
    "                               86, 84, 88, 87, 83, 85, 89, 86, 84, 88,\n",
    "                               87, 83, 85, 89, 86, 84, 88, 87, 83, 85,\n",
    "                               89, 86, 84, 88, 87, 83, 85, 89, 86, 84,\n",
    "                               88, 87, 83, 85, 89, 86, 84, 88, 87, 83])\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df8ef3-c6ad-4c99-99d1-9ce2b1145ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 12\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
